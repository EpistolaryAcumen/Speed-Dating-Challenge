{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "os.chdir('/Users/wynnephilpott/Documents/missing pauldron/Data Science/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dfs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iid', 'gender', 'order', 'partner', 'pid', 'match', 'int_corr',\n",
       "       'samerace', 'age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int',\n",
       "       'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'dec_o', 'attr_o', 'sinc_o',\n",
       "       'intel_o', 'fun_o', 'amb_o', 'like_o', 'prob_o', 'met_o', 'dec', 'attr',\n",
       "       'sinc', 'intel', 'fun', 'amb', 'like', 'prob', 'met'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'o's stand for parter's ratings so get rid of them (except for race, age) for a model that is to predict what the actual person(not the parter) will do. Daters were given 4-5 minutes with each partner. After they spoke, the daters then rated their parters on 'attr','sinc', 'intel', 'fun', 'amb'. Additionally, they put down how much they like the person (score from 1 to 10) and finally how probable they thought that thier partner liked them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['int_corr','attr','samerace', 'age_o', 'race_o','sinc', 'intel', 'fun', 'amb', 'like', 'prob', 'met']]\n",
    "\n",
    "y = df['dec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our training and test sets for our machine learning algorithms. We'll start with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lgm = LogisticRegression()\n",
    "lgm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report as cr\n",
    "from sklearn.metrics import confusion_matrix as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1077\n",
      "           1       0.72      0.70      0.71       781\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1858\n",
      "   macro avg       0.75      0.75      0.75      1858\n",
      "weighted avg       0.76      0.76      0.76      1858\n",
      "\n",
      "[[864 213]\n",
      " [235 546]]\n"
     ]
    }
   ],
   "source": [
    "print(cr(y_test,pred))\n",
    "print(cm(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to use F1 score weighted average as it considers both precision and recall. This will be how I measure model success. Let's try to bump up that .76!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496559\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "#I want to see a summary of the coefficients of this model\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "model = sm.Logit(y_train, X_train)\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>dec</td>       <th>  No. Observations:  </th>  <td>  4335</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4323</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 19 May 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.2759</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:52:02</td>     <th>  Log-Likelihood:    </th> <td> -2152.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -2972.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>int_corr</th> <td>   -0.0381</td> <td>    0.124</td> <td>   -0.306</td> <td> 0.759</td> <td>   -0.282</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>attr</th>     <td>    0.3767</td> <td>    0.028</td> <td>   13.421</td> <td> 0.000</td> <td>    0.322</td> <td>    0.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>samerace</th> <td>   -0.3114</td> <td>    0.079</td> <td>   -3.947</td> <td> 0.000</td> <td>   -0.466</td> <td>   -0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_o</th>    <td>   -0.1325</td> <td>    0.008</td> <td>  -17.167</td> <td> 0.000</td> <td>   -0.148</td> <td>   -0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race_o</th>   <td>   -0.1894</td> <td>    0.030</td> <td>   -6.238</td> <td> 0.000</td> <td>   -0.249</td> <td>   -0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sinc</th>     <td>   -0.2276</td> <td>    0.033</td> <td>   -6.943</td> <td> 0.000</td> <td>   -0.292</td> <td>   -0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intel</th>    <td>   -0.1225</td> <td>    0.039</td> <td>   -3.103</td> <td> 0.002</td> <td>   -0.200</td> <td>   -0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fun</th>      <td>    0.0980</td> <td>    0.031</td> <td>    3.119</td> <td> 0.002</td> <td>    0.036</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amb</th>      <td>   -0.1682</td> <td>    0.030</td> <td>   -5.550</td> <td> 0.000</td> <td>   -0.228</td> <td>   -0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>like</th>     <td>    0.5994</td> <td>    0.039</td> <td>   15.558</td> <td> 0.000</td> <td>    0.524</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prob</th>     <td>    0.1595</td> <td>    0.022</td> <td>    7.358</td> <td> 0.000</td> <td>    0.117</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>met</th>      <td>   -0.0712</td> <td>    0.038</td> <td>   -1.863</td> <td> 0.062</td> <td>   -0.146</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                    dec   No. Observations:                 4335\n",
       "Model:                          Logit   Df Residuals:                     4323\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Sun, 19 May 2019   Pseudo R-squ.:                  0.2759\n",
       "Time:                        15:52:02   Log-Likelihood:                -2152.6\n",
       "converged:                       True   LL-Null:                       -2972.7\n",
       "                                        LLR p-value:                     0.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "int_corr      -0.0381      0.124     -0.306      0.759      -0.282       0.206\n",
       "attr           0.3767      0.028     13.421      0.000       0.322       0.432\n",
       "samerace      -0.3114      0.079     -3.947      0.000      -0.466      -0.157\n",
       "age_o         -0.1325      0.008    -17.167      0.000      -0.148      -0.117\n",
       "race_o        -0.1894      0.030     -6.238      0.000      -0.249      -0.130\n",
       "sinc          -0.2276      0.033     -6.943      0.000      -0.292      -0.163\n",
       "intel         -0.1225      0.039     -3.103      0.002      -0.200      -0.045\n",
       "fun            0.0980      0.031      3.119      0.002       0.036       0.160\n",
       "amb           -0.1682      0.030     -5.550      0.000      -0.228      -0.109\n",
       "like           0.5994      0.039     15.558      0.000       0.524       0.675\n",
       "prob           0.1595      0.022      7.358      0.000       0.117       0.202\n",
       "met           -0.0712      0.038     -1.863      0.062      -0.146       0.004\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Females**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our findings from the EDA, it makes sense that we should apply one model to Females and a different one to males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = df[df['gender']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       582\n",
      "           1       0.68      0.58      0.63       348\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       930\n",
      "   macro avg       0.72      0.71      0.71       930\n",
      "weighted avg       0.73      0.74      0.74       930\n",
      "\n",
      "[[485  97]\n",
      " [145 203]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = female[['int_corr','attr','samerace', 'age_o', 'race_o','sinc', 'intel', 'fun', 'amb', 'like', 'prob', 'met']]\n",
    "y = female['dec']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "\n",
    "lgm.fit(X_train,y_train)\n",
    "pred = lgm.predict(X_test)\n",
    "\n",
    "print(cr(y_test,pred))\n",
    "print(cm(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Males**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = df[df['gender']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       481\n",
      "           1       0.77      0.82      0.80       448\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       929\n",
      "   macro avg       0.80      0.80      0.80       929\n",
      "weighted avg       0.80      0.80      0.80       929\n",
      "\n",
      "[[373 108]\n",
      " [ 81 367]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = male[['int_corr','attr','samerace', 'age_o', 'race_o','sinc', 'intel', 'fun', 'amb', 'like', 'prob', 'met']]\n",
    "y = male['dec']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "\n",
    "lgm.fit(X_train,y_train)\n",
    "pred = lgm.predict(X_test)\n",
    "\n",
    "print(cr(y_test,pred))\n",
    "print(cm(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad actually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do partitioning beyond male/female and later attempt to engineer features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
